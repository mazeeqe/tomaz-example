{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a666bab6-96eb-4ff5-af18-9e50e2412cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c97c231-e10f-47ff-997c-bd95ae8d5854",
   "metadata": {},
   "source": [
    "# Monte Carlo Weights\n",
    "To calculate the weights it's necessary to get the production rate for each file.\n",
    "I commented out the functions to create the csv since I already got the needed csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ba851f-2068-49f3-b31e-f245a38ad438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(url):\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "    table = soup.find(\"table\")  # the big summary table\n",
    "    return table\n",
    "\n",
    "url = \"https://ild.ngt.ndu.ac.jp/mc-prod/prodmon/prodsum-mc2020.html\"\n",
    "\n",
    "# Since I already created the csv\n",
    "#table = extract_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758cdeea-0c31-4658-a055-7e9e7531a7ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prod_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m         tds \u001b[38;5;241m=\u001b[39m [td\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m td \u001b[38;5;129;01min\u001b[39;00m tr\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Build row with current_rate\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend([current_rate,\u001b[43mprod_val\u001b[49m,gen_val] \u001b[38;5;241m+\u001b[39m tds)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Write CSV\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m250-SetA-with-rate.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m,newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prod_val' is not defined"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "current_rate = None\n",
    "\n",
    "pattern = r'(\\d+)\\s*/\\s*(\\d+)'\n",
    "\n",
    "def create_csv():\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        text = tr.get_text(strip=True)\n",
    "        # Detect section header with produced rate\n",
    "        if \":\" in text and \"Produced rate\" in text:\n",
    "            # e.g., \"higgs_inclusive : Produced rate 99.96% (…)\"\n",
    "            parts = text.split(\":\")\n",
    "            current_rate = parts[1].strip().split()[2]\n",
    "    \n",
    "            matches = re.findall(pattern, parts[1].strip())\n",
    "    \n",
    "            # If you expect only one occurrence, you can take the first match:\n",
    "            if matches:\n",
    "                prod, gen = matches[0]          # strings representing the numbers\n",
    "                prod_val = int(prod)            # convert to integers if needed\n",
    "                gen_val  = int(gen)\n",
    "    \n",
    "                print(f\"{current_rate}\")\n",
    "                print(f\"N_Prod = {prod_val}\")\n",
    "                print(f\"N_Gen  = {gen_val}\")\n",
    "            else:\n",
    "                print(\"No number pair found.\")\n",
    "        elif tr.find_all(\"td\"):\n",
    "            tds = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "            # Build row with current_rate\n",
    "            rows.append([current_rate,prod_val,gen_val] + tds)\n",
    "    \n",
    "    \n",
    "    # Write CSV\n",
    "    with open(\"250-SetA-with-rate.csv\",\"w\",newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"ProducedRate\",\"n_prod\",\"n_gen\",\"pol\",\"processID\",\"NbEvents\",\"int.lumi\",\n",
    "                         \"Done%\",\"ElogID\",\"ProdIDs\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "#create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55ce245-84a0-4756-b9b2-4a29073a96bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProducedRate</th>\n",
       "      <th>n_prod</th>\n",
       "      <th>n_gen</th>\n",
       "      <th>process_type</th>\n",
       "      <th>pol</th>\n",
       "      <th>processID</th>\n",
       "      <th>NbEvents</th>\n",
       "      <th>int.lumi(1/fb)</th>\n",
       "      <th>Done %</th>\n",
       "      <th>ElogID(s)</th>\n",
       "      <th>ProdIDs of DST and REC files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.96%</td>\n",
       "      <td>6997400</td>\n",
       "      <td>7000000</td>\n",
       "      <td>e1e1h</td>\n",
       "      <td>eL.pL</td>\n",
       "      <td>402013</td>\n",
       "      <td>500000</td>\n",
       "      <td>801943</td>\n",
       "      <td>100.0</td>\n",
       "      <td>348</td>\n",
       "      <td>DST=15095,15096;REC=15095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.96%</td>\n",
       "      <td>6997400</td>\n",
       "      <td>7000000</td>\n",
       "      <td>e1e1h</td>\n",
       "      <td>eL.pR</td>\n",
       "      <td>402001</td>\n",
       "      <td>500000</td>\n",
       "      <td>28294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>347</td>\n",
       "      <td>DST=15089,15090;REC=15089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.96%</td>\n",
       "      <td>6997400</td>\n",
       "      <td>7000000</td>\n",
       "      <td>e1e1h</td>\n",
       "      <td>eR.pL</td>\n",
       "      <td>402002</td>\n",
       "      <td>500000</td>\n",
       "      <td>44887</td>\n",
       "      <td>100.0</td>\n",
       "      <td>347</td>\n",
       "      <td>DST=15089,15090;REC=15089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.96%</td>\n",
       "      <td>6997400</td>\n",
       "      <td>7000000</td>\n",
       "      <td>e1e1h</td>\n",
       "      <td>eR.pR</td>\n",
       "      <td>402014</td>\n",
       "      <td>498800</td>\n",
       "      <td>800018</td>\n",
       "      <td>99.8</td>\n",
       "      <td>348</td>\n",
       "      <td>DST=15095,15096;REC=15095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.96%</td>\n",
       "      <td>6997400</td>\n",
       "      <td>7000000</td>\n",
       "      <td>e2e2h</td>\n",
       "      <td>eL.pR</td>\n",
       "      <td>402003</td>\n",
       "      <td>500000</td>\n",
       "      <td>29462</td>\n",
       "      <td>100.0</td>\n",
       "      <td>347</td>\n",
       "      <td>DST=15089,15090;REC=15089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProducedRate   n_prod    n_gen process_type    pol  processID  NbEvents  \\\n",
       "0       99.96%  6997400  7000000        e1e1h  eL.pL     402013    500000   \n",
       "1       99.96%  6997400  7000000        e1e1h  eL.pR     402001    500000   \n",
       "2       99.96%  6997400  7000000        e1e1h  eR.pL     402002    500000   \n",
       "3       99.96%  6997400  7000000        e1e1h  eR.pR     402014    498800   \n",
       "4       99.96%  6997400  7000000        e2e2h  eL.pR     402003    500000   \n",
       "\n",
       "   int.lumi(1/fb)  Done % ElogID(s) ProdIDs of DST and REC files  \n",
       "0          801943   100.0       348    DST=15095,15096;REC=15095  \n",
       "1           28294   100.0       347    DST=15089,15090;REC=15089  \n",
       "2           44887   100.0       347    DST=15089,15090;REC=15089  \n",
       "3          800018    99.8       348    DST=15095,15096;REC=15095  \n",
       "4           29462   100.0       347    DST=15089,15090;REC=15089  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Option 1 – absolute path (replace USERNAME with your actual login name)\n",
    "csv_path = \"/home/USERNAME/Documents/mestrado/code/tomaz-example/data/mc_tree/250-SetA-with-rate.csv\"\n",
    "\n",
    "# Option 2 – expand a tilde‑prefixed path\n",
    "csv_path = os.path.expanduser(\"~/Documents/mestrado/code/tomaz-example/data/mc_tree/250-SetA-with-rate.csv\")\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278eccf8-bb6c-4655-baa8-f5a7e006d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cross section found in https://ild.ngt.ndu.ac.jp/CDS/mc-dbd.log/generated/metainfo-id/I500183.txt\n",
      "Written cross sections to cross_sections_250GeV.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import csv\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# List your generator metadata URLs here (replace with actual ones).\n",
    "# They should point to ELOG pages that contain cross section info.\n",
    "genmeta_urls = [\n",
    "    # e.g.\n",
    "    \"https://ild.ngt.ndu.ac.jp/CDS/mc-dbd.log/generated/metainfo-id/I500183.txt\",\n",
    "    # \"https://ild.ngt.ndu.ac.jp/mc-prod/elog/genmeta/5678\",\n",
    "    # ...\n",
    "]\n",
    "\n",
    "output_csv = \"cross_sections_250GeV.csv\"\n",
    "\n",
    "# Regex to find the cross section line (case-insensitive)\n",
    "xsec_re = re.compile(r\"([Cc]ross [Ss]ection)\\s*[:=]\\s*([\\d\\.Ee+-]+)\\s*(pb)\", re.IGNORECASE)\n",
    "\n",
    "results = []\n",
    "\n",
    "for url in genmeta_urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        text = response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Find the dataset identifier — use the URL path if no explicit name\n",
    "    dataset = urlparse(url).path.split(\"/\")[-1]\n",
    "\n",
    "    # Search for a cross section\n",
    "    match = xsec_re.search(text)\n",
    "    if match:\n",
    "        xsec_val = float(match.group(2))\n",
    "        units = match.group(3)\n",
    "        results.append((dataset, xsec_val, units, url))\n",
    "    else:\n",
    "        print(f\"No cross section found in {url}\")\n",
    "\n",
    "# Save to CSV\n",
    "with open(output_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"dataset\", \"cross_section_pb\", \"units\", \"source_url\"])\n",
    "    for row in results:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Written cross sections to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4653f3-c3f8-451b-8719-40ac85ad7606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
